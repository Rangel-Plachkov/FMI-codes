{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSUXAYISHmPESMOA/wwYyX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"XhyCePqDy23W"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch.nn import functional as F"],"metadata":{"id":"ZBNhRk8RzXNE","executionInfo":{"status":"ok","timestamp":1748454124427,"user_tz":-180,"elapsed":4,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cHT5cXS7zgQV","executionInfo":{"status":"ok","timestamp":1748451101678,"user_tz":-180,"elapsed":22969,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"65cda93f-a59d-4e4d-cf36-6dbf431640a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Task 1\n"],"metadata":{"id":"iwWUJdNVzV7d"}},{"cell_type":"code","source":["file_path = '/content/drive/My Drive/DL_24-25/Data/shakespere.txt'\n","\n","with open(file_path, 'r') as file:\n","  text = file.read()\n","\n","print(len(text))\n","print(text[:1000])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wa8oz3fezY1p","executionInfo":{"status":"ok","timestamp":1748451243282,"user_tz":-180,"elapsed":5,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"60cf09b9-b52d-4d7f-c5f1-2b81adf3eb21"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1115393\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor citizens, the patricians good.\n","What authority surfeits on would relieve us: if they\n","would yield us but the superfluity, while it were\n","wholesome, we might guess they relieved us humanely;\n","but they think we are too dear: the leanness that\n","afflicts us, the object of our misery, is as an\n","inventory to particularise their abundance; our\n","sufferance is a gain to them Let us revenge this with\n","our pikes, ere we become rakes: for the gods know I\n","speak this in hunger for bread, not in thirst for revenge.\n","\n","\n"]}]},{"cell_type":"markdown","source":["# Task 2"],"metadata":{"id":"LnMo-BYO0SJQ"}},{"cell_type":"code","source":["vocabulary = sorted(set(text))\n","print(f'Vocabulary size: {len(vocabulary)}')\n","print(''.join(vocabulary))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ay5U8bAO0Tz9","executionInfo":{"status":"ok","timestamp":1748451467013,"user_tz":-180,"elapsed":14,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"d83fe6bf-642f-4933-a994-ede3bab20633"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 65\n","\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"]}]},{"cell_type":"markdown","source":["# Task 3"],"metadata":{"id":"Bv8CaWr31F04"}},{"cell_type":"code","source":["itos = dict(enumerate(vocabulary))\n","\n","\n","stoi = {chr: idx for idx, chr in itos.items()}\n","\n","def token_to_id(token):\n","  return [stoi[chr] for chr in token]\n","\n","def id_to_token(id):\n","  return ''.join([itos[idx] for idx in id])\n","\n","\n","res = token_to_id('hi therre')\n","print(res)\n","print(id_to_token(res))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EdPf6Uaf1G5M","executionInfo":{"status":"ok","timestamp":1748452758367,"user_tz":-180,"elapsed":51,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"488a1ba0-b231-4bb8-98f9-f6b00fae02d5"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["[46, 47, 1, 58, 46, 43, 56, 56, 43]\n","hi therre\n"]}]},{"cell_type":"markdown","source":["# Task 4"],"metadata":{"id":"bje4L8om5PER"}},{"cell_type":"code","source":["file_path = '/content/drive/My Drive/DL_24-25/Data/shakespere.txt'\n","\n","with open(file_path, 'r') as file:\n","  text = file.read()\n","\n","\n","text_tokenised = token_to_id(text)\n","text_tokenised_tensor = torch.tensor(text_tokenised, dtype=torch.int64)\n","print(f'Shape of result:{text_tokenised_tensor.shape}') #My text is 1 character smaller than yours\n","print(text_tokenised_tensor[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynq5TNt45QB-","executionInfo":{"status":"ok","timestamp":1748453004344,"user_tz":-180,"elapsed":315,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"f1f730c3-2208-47eb-ef59-27e2cf404396"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["1115393\n","Shape of result:torch.Size([1115393])\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n","         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n","        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n","        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n","         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n","         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n","        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n","        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n","         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n","        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n","        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n","        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n","        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n","        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n","        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n","         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n","         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n","         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n","        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n","        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n","        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n","        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n","        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n","        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n","         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n","         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n","        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n","        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n","        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n","         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n","        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n","        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n","         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n","        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n","        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n","        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n","        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n","        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n","        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n","        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n","        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n","        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n","         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n","        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n","        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n","        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n","        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n","        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n","        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"]}]},{"cell_type":"markdown","source":["# Task 5"],"metadata":{"id":"Cv-hynrQ7Qgg"}},{"cell_type":"code","source":["split_idx = int(0.9 * len(text_tokenised_tensor))\n","train_data = text_tokenised_tensor[:split_idx]\n","test_data = text_tokenised_tensor[split_idx:]\n","\n","print(f'Shape of dataset for training : {train_data.shape}')\n","print(f'Shape of dataset for testing :  {test_data.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IBFFF_d07SQM","executionInfo":{"status":"ok","timestamp":1748453408965,"user_tz":-180,"elapsed":4,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"bba5899a-24ba-41ff-f773-78147d19e1f4"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of dataset for training : torch.Size([1003853])\n","Shape of dataset for testing :  torch.Size([111540])\n"]}]},{"cell_type":"markdown","source":["# Task 6"],"metadata":{"id":"0WjKgVEv8lp9"}},{"cell_type":"code","source":["from random import sample\n","block_size = 8\n","\n","\n","def get_sample(text_tensor, idx, block_size = 8):\n","  X = text_tensor[max(0, idx - block_size):idx+1]\n","  y = text_tensor[idx+1]\n","  return X,y\n","\n","\n","samples = []\n","for i in range(9):\n","  samples.append(get_sample(train_data, i, block_size))\n","\n","for i in range(8):\n","  X, y = samples[i]\n","  print(f'Sample {i}: {X} , predict: {y}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w--Yg9jH8mtK","executionInfo":{"status":"ok","timestamp":1748454519645,"user_tz":-180,"elapsed":59,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"e9c6f20e-3778-4092-af59-a28eb3e061bb"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 0: tensor([18]) , predict: 47\n","Sample 1: tensor([18, 47]) , predict: 56\n","Sample 2: tensor([18, 47, 56]) , predict: 57\n","Sample 3: tensor([18, 47, 56, 57]) , predict: 58\n","Sample 4: tensor([18, 47, 56, 57, 58]) , predict: 1\n","Sample 5: tensor([18, 47, 56, 57, 58,  1]) , predict: 15\n","Sample 6: tensor([18, 47, 56, 57, 58,  1, 15]) , predict: 47\n","Sample 7: tensor([18, 47, 56, 57, 58,  1, 15, 47]) , predict: 58\n"]}]},{"cell_type":"markdown","source":["# Task 7"],"metadata":{"id":"Vm_B37a4AhyS"}},{"cell_type":"code","source":["torch.manual_seed(42)\n","batch_size = 4\n","\n","def get_batch(text_tensor, block_size = 8):\n","  idx = torch.randint(0, len(text_tensor) - block_size, (batch_size,))\n"],"metadata":{"id":"ZMu4PT-rAtAN"},"execution_count":null,"outputs":[]}]}