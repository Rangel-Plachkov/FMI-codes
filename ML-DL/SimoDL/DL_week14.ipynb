{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSFzxmo3+BU4wnLIym0a3g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"XhyCePqDy23W"}},{"cell_type":"code","source":["import random\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"],"metadata":{"id":"ZBNhRk8RzXNE","executionInfo":{"status":"ok","timestamp":1748884119852,"user_tz":-180,"elapsed":3,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cHT5cXS7zgQV","executionInfo":{"status":"ok","timestamp":1748881473358,"user_tz":-180,"elapsed":23200,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"a468196a-c605-41c4-99dc-6167e823948f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Task 1\n"],"metadata":{"id":"iwWUJdNVzV7d"}},{"cell_type":"code","source":["file_path = \"/content/shakespeare.txt\"\n","\n","with open(file_path, 'r') as file:\n","  text = file.read()\n","\n","print(len(text))\n","print(text[:1000])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wa8oz3fezY1p","executionInfo":{"status":"ok","timestamp":1748883042486,"user_tz":-180,"elapsed":7,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"d5b98d5b-b024-4079-a202-700ecc9c0109"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["1115394\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor citizens, the patricians good.\n","What authority surfeits on would relieve us: if they\n","would yield us but the superfluity, while it were\n","wholesome, we might guess they relieved us humanely;\n","but they think we are too dear: the leanness that\n","afflicts us, the object of our misery, is as an\n","inventory to particularise their abundance; our\n","sufferance is a gain to them Let us revenge this with\n","our pikes, ere we become rakes: for the gods know I\n","speak this in hunger for bread, not in thirst for revenge.\n","\n","\n"]}]},{"cell_type":"markdown","source":["# Task 2"],"metadata":{"id":"LnMo-BYO0SJQ"}},{"cell_type":"code","source":["vocabulary = sorted(set(text))\n","print(f'Vocabulary size: {len(vocabulary)}')\n","print(''.join(vocabulary))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ay5U8bAO0Tz9","executionInfo":{"status":"ok","timestamp":1748883047287,"user_tz":-180,"elapsed":4,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"d52a28a6-0c15-4ce9-a9a6-75caee24fe2a"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 65\n","\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"]}]},{"cell_type":"markdown","source":["# Task 3"],"metadata":{"id":"Bv8CaWr31F04"}},{"cell_type":"code","source":["itos = dict(enumerate(vocabulary))\n","\n","\n","stoi = {chr: idx for idx, chr in itos.items()}\n","\n","def token_to_id(token):\n","  return [stoi[chr] for chr in token]\n","\n","def id_to_token(id):\n","  return ''.join([itos[idx] for idx in id])\n","\n","\n","res = token_to_id('hi therre')\n","print(res)\n","print(id_to_token(res))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EdPf6Uaf1G5M","executionInfo":{"status":"ok","timestamp":1748883048432,"user_tz":-180,"elapsed":22,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"cd840e02-1eee-4a6e-e42b-3950be609b96"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["[46, 47, 1, 58, 46, 43, 56, 56, 43]\n","hi therre\n"]}]},{"cell_type":"markdown","source":["# Task 4"],"metadata":{"id":"bje4L8om5PER"}},{"cell_type":"code","source":["file_path = \"/content/shakespeare.txt\"\n","\n","with open(file_path, 'r') as file:\n","  text = file.read()\n","\n","\n","text_tokenised = token_to_id(text)\n","text_tokenised_tensor = torch.tensor(text_tokenised, dtype=torch.int64)\n","print(f'Shape of result:{text_tokenised_tensor.shape}') #My text is 1 character smaller than yours\n","print(text_tokenised_tensor[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynq5TNt45QB-","executionInfo":{"status":"ok","timestamp":1748883050944,"user_tz":-180,"elapsed":285,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"3fd1cd3c-ba26-4529-cd7e-8961b9ef25aa"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of result:torch.Size([1115394])\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n","         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n","        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n","        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n","         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n","         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n","        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n","        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n","         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n","        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n","        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n","        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n","        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n","        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n","        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n","         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n","         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n","         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n","        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n","        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n","        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n","        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n","        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n","        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n","         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n","         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n","        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n","        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n","        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n","         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n","        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n","        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n","         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n","        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n","        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n","        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n","        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n","        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n","        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n","        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n","        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n","        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n","         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n","        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n","        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n","        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n","        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n","        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n","        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"]}]},{"cell_type":"markdown","source":["# Task 5"],"metadata":{"id":"Cv-hynrQ7Qgg"}},{"cell_type":"code","source":["split_idx = int(0.9 * len(text_tokenised_tensor))\n","train_data = text_tokenised_tensor[:split_idx]\n","test_data = text_tokenised_tensor[split_idx:]\n","\n","print(f'Shape of dataset for training : {train_data.shape}')\n","print(f'Shape of dataset for testing :  {test_data.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IBFFF_d07SQM","executionInfo":{"status":"ok","timestamp":1748883053442,"user_tz":-180,"elapsed":14,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"271af9d6-4668-49a5-9820-937ad6a831a6"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of dataset for training : torch.Size([1003854])\n","Shape of dataset for testing :  torch.Size([111540])\n"]}]},{"cell_type":"markdown","source":["# Task 6"],"metadata":{"id":"0WjKgVEv8lp9"}},{"cell_type":"code","source":["from random import sample\n","block_size = 8\n","\n","\n","def get_sample(text_tensor, idx, block_size = 8):\n","  X = text_tensor[max(0, idx - block_size):idx+1]\n","  y = text_tensor[idx+1]\n","  return X,y\n","\n","\n","samples = []\n","for i in range(9):\n","  samples.append(get_sample(train_data, i, block_size))\n","\n","for i in range(8):\n","  X, y = samples[i]\n","  print(f'Sample {i}: {X} , predict: {y}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w--Yg9jH8mtK","executionInfo":{"status":"ok","timestamp":1748883054957,"user_tz":-180,"elapsed":5,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"89045acf-20ed-4c29-8557-003cccd590b7"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 0: tensor([18]) , predict: 47\n","Sample 1: tensor([18, 47]) , predict: 56\n","Sample 2: tensor([18, 47, 56]) , predict: 57\n","Sample 3: tensor([18, 47, 56, 57]) , predict: 58\n","Sample 4: tensor([18, 47, 56, 57, 58]) , predict: 1\n","Sample 5: tensor([18, 47, 56, 57, 58,  1]) , predict: 15\n","Sample 6: tensor([18, 47, 56, 57, 58,  1, 15]) , predict: 47\n","Sample 7: tensor([18, 47, 56, 57, 58,  1, 15, 47]) , predict: 58\n"]}]},{"cell_type":"markdown","source":["# Task 7"],"metadata":{"id":"Vm_B37a4AhyS"}},{"cell_type":"code","source":["!wget raw.githubusercontent.com/SimeonHristov99/DL_24-25/refs/heads/main/DATA/shakespeare.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H47WY-0bjJHP","executionInfo":{"status":"ok","timestamp":1748882994369,"user_tz":-180,"elapsed":359,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"cb4e2207-41d5-407b-8933-0c0f5bf2f86c"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-06-02 16:49:52--  http://raw.githubusercontent.com/SimeonHristov99/DL_24-25/refs/heads/main/DATA/shakespeare.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/SimeonHristov99/DL_24-25/refs/heads/main/DATA/shakespeare.txt [following]\n","--2025-06-02 16:49:52--  https://raw.githubusercontent.com/SimeonHristov99/DL_24-25/refs/heads/main/DATA/shakespeare.txt\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘shakespeare.txt’\n","\n","\rshakespeare.txt       0%[                    ]       0  --.-KB/s               \rshakespeare.txt     100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n","\n","2025-06-02 16:49:53 (98.3 MB/s) - ‘shakespeare.txt’ saved [1115394/1115394]\n","\n"]}]},{"cell_type":"code","source":["torch.Tensor(batch_size, block_size).type_as(torch.int64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"DKoJ586czsSP","executionInfo":{"status":"error","timestamp":1748887437141,"user_tz":-180,"elapsed":25,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"56dd6f3f-b2d3-4962-a1e7-364def63e88b"},"execution_count":139,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"type_as(): argument 'other' (position 1) must be Tensor, not torch.dtype","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-139-6fc7a0d3b696>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: type_as(): argument 'other' (position 1) must be Tensor, not torch.dtype"]}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","batch_size = 4\n","\n","def get_batch(text_tensor, block_size = 8, batch_size = 4):\n","  idxs = torch.randint(0, len(text_tensor) - block_size, (batch_size,))\n","  Xs, Ys = torch.Tensor(batch_size, block_size).astype('int'), torch.Tensor(batch_size, block_size).astype('int')\n","  for i in range(batch_size):\n","    Xs[i] = text_tensor[idxs[i]:idxs[i]+block_size]\n","    Ys[i] = text_tensor[idxs[i]+1:idxs[i]+block_size+1]\n","  return Xs, Ys\n","\n","Xs, Ys = get_batch(text_tokenised_tensor)\n","print(Xs)\n","print(Ys)\n","\n","def get_sample(Xs, Ys, idx):\n","  X = Xs[idx // block_size][0:(idx % block_size + 1)]\n","  y = Ys[idx // block_size][(idx % block_size)]\n","  return X,y\n","\n","\n","for i in range(32):\n","  X, y = get_sample(Xs, Ys, i)\n","  print(f'Sample {i}: {X} , predict: {y}')\n"],"metadata":{"id":"ZMu4PT-rAtAN","colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"status":"error","timestamp":1748887288115,"user_tz":-180,"elapsed":9,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"6934009a-1500-49a2-e730-278b00e96de5"},"execution_count":131,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'Tensor' object has no attribute 'astype'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-131-e1d11e8be7c7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_tokenised_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-131-e1d11e8be7c7>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(text_tensor, block_size, batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"]}]},{"cell_type":"markdown","source":["# Task 8"],"metadata":{"id":"WVhDhHDzjfOr"}},{"cell_type":"code","source":["Xs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1IuU6lWy-E1","executionInfo":{"status":"ok","timestamp":1748887137418,"user_tz":-180,"elapsed":47,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"8010817a-b871-4653-f7c0-67d13cf0dab3"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[42.,  1., 58., 46., 59., 57.,  1., 21.],\n","        [54., 56., 47., 43., 57., 58., 11.,  0.],\n","        [49., 47., 52., 45., 12.,  1., 58., 46.],\n","        [58., 46., 53., 59., 58.,  1., 56., 43.]])"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["embedding_table = nn.Embedding(len(vocabulary), len(vocabulary))\n","logit = embedding_table(Xs)\n","print(logit.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"eSRj0nbfji-W","executionInfo":{"status":"error","timestamp":1748887015689,"user_tz":-180,"elapsed":242,"user":{"displayName":"Rangel Plachkov","userId":"10069740936871026328"}},"outputId":"6ec57053-1ed1-4722-e36f-8fc440d8d1dd"},"execution_count":125,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-d394c5366b19>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"]}]}]}